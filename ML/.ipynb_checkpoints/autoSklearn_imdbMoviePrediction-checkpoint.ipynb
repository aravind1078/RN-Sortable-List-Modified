{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>class</th>\n",
       "      <th>votes</th>\n",
       "      <th>budget</th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169</td>\n",
       "      <td>309404152</td>\n",
       "      <td>471220</td>\n",
       "      <td>300000000</td>\n",
       "      <td>2007</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>102055</td>\n",
       "      <td>24570</td>\n",
       "      <td>300000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>73058679</td>\n",
       "      <td>212204</td>\n",
       "      <td>263700000</td>\n",
       "      <td>2012</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>200807262</td>\n",
       "      <td>294810</td>\n",
       "      <td>260000000</td>\n",
       "      <td>2010</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156</td>\n",
       "      <td>336530303</td>\n",
       "      <td>383056</td>\n",
       "      <td>258000000</td>\n",
       "      <td>2007</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156</td>\n",
       "      <td>336530303</td>\n",
       "      <td>383071</td>\n",
       "      <td>258000000</td>\n",
       "      <td>2007</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>164</td>\n",
       "      <td>448130642</td>\n",
       "      <td>1144337</td>\n",
       "      <td>250000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>141</td>\n",
       "      <td>458991599</td>\n",
       "      <td>462669</td>\n",
       "      <td>250000000</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>153</td>\n",
       "      <td>301956980</td>\n",
       "      <td>321795</td>\n",
       "      <td>250000000</td>\n",
       "      <td>2009</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>183</td>\n",
       "      <td>330249062</td>\n",
       "      <td>371639</td>\n",
       "      <td>250000000</td>\n",
       "      <td>2016</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>136</td>\n",
       "      <td>241063875</td>\n",
       "      <td>370704</td>\n",
       "      <td>250000000</td>\n",
       "      <td>2011</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>164</td>\n",
       "      <td>255108370</td>\n",
       "      <td>354228</td>\n",
       "      <td>250000000</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>147</td>\n",
       "      <td>407197282</td>\n",
       "      <td>272670</td>\n",
       "      <td>250000000</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>148</td>\n",
       "      <td>200074175</td>\n",
       "      <td>275868</td>\n",
       "      <td>245000000</td>\n",
       "      <td>2015</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>178</td>\n",
       "      <td>760505847</td>\n",
       "      <td>886204</td>\n",
       "      <td>237000000</td>\n",
       "      <td>2009</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>153</td>\n",
       "      <td>262030663</td>\n",
       "      <td>451803</td>\n",
       "      <td>230000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>151</td>\n",
       "      <td>423032628</td>\n",
       "      <td>522040</td>\n",
       "      <td>225000000</td>\n",
       "      <td>2006</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>143</td>\n",
       "      <td>291021565</td>\n",
       "      <td>548573</td>\n",
       "      <td>225000000</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>150</td>\n",
       "      <td>141614023</td>\n",
       "      <td>149922</td>\n",
       "      <td>225000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>106</td>\n",
       "      <td>179020854</td>\n",
       "      <td>268154</td>\n",
       "      <td>225000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>186</td>\n",
       "      <td>258355354</td>\n",
       "      <td>483540</td>\n",
       "      <td>225000000</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>173</td>\n",
       "      <td>623279547</td>\n",
       "      <td>995415</td>\n",
       "      <td>220000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>173</td>\n",
       "      <td>623279547</td>\n",
       "      <td>995415</td>\n",
       "      <td>220000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>150</td>\n",
       "      <td>89289910</td>\n",
       "      <td>181792</td>\n",
       "      <td>215000000</td>\n",
       "      <td>2013</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>130</td>\n",
       "      <td>234903076</td>\n",
       "      <td>175409</td>\n",
       "      <td>215000000</td>\n",
       "      <td>2013</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>130</td>\n",
       "      <td>234903076</td>\n",
       "      <td>175413</td>\n",
       "      <td>215000000</td>\n",
       "      <td>2013</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>104</td>\n",
       "      <td>234360014</td>\n",
       "      <td>383427</td>\n",
       "      <td>210000000</td>\n",
       "      <td>2006</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>165</td>\n",
       "      <td>245428137</td>\n",
       "      <td>242420</td>\n",
       "      <td>210000000</td>\n",
       "      <td>2014</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>169</td>\n",
       "      <td>200069408</td>\n",
       "      <td>240396</td>\n",
       "      <td>209000000</td>\n",
       "      <td>2006</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>131</td>\n",
       "      <td>65173160</td>\n",
       "      <td>202382</td>\n",
       "      <td>209000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>103</td>\n",
       "      <td>53991137</td>\n",
       "      <td>202800</td>\n",
       "      <td>1500000</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>114</td>\n",
       "      <td>1221261</td>\n",
       "      <td>38215</td>\n",
       "      <td>1500000</td>\n",
       "      <td>2000</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>104</td>\n",
       "      <td>3447339</td>\n",
       "      <td>29517</td>\n",
       "      <td>1500000</td>\n",
       "      <td>2013</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>98</td>\n",
       "      <td>406035</td>\n",
       "      <td>30314</td>\n",
       "      <td>1500000</td>\n",
       "      <td>2001</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>100</td>\n",
       "      <td>373967</td>\n",
       "      <td>43839</td>\n",
       "      <td>1500000</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>84</td>\n",
       "      <td>173066</td>\n",
       "      <td>21379</td>\n",
       "      <td>1500000</td>\n",
       "      <td>2007</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>95</td>\n",
       "      <td>3478</td>\n",
       "      <td>22212</td>\n",
       "      <td>1500000</td>\n",
       "      <td>2008</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>105</td>\n",
       "      <td>1647780</td>\n",
       "      <td>65951</td>\n",
       "      <td>1300000</td>\n",
       "      <td>1998</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>95</td>\n",
       "      <td>695229</td>\n",
       "      <td>11369</td>\n",
       "      <td>1300000</td>\n",
       "      <td>1996</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>103</td>\n",
       "      <td>55153403</td>\n",
       "      <td>299127</td>\n",
       "      <td>1200000</td>\n",
       "      <td>2004</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>100</td>\n",
       "      <td>18488314</td>\n",
       "      <td>76151</td>\n",
       "      <td>1200000</td>\n",
       "      <td>2001</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>111</td>\n",
       "      <td>9180275</td>\n",
       "      <td>22145</td>\n",
       "      <td>1200000</td>\n",
       "      <td>2000</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>85</td>\n",
       "      <td>2199853</td>\n",
       "      <td>19986</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1999</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>102</td>\n",
       "      <td>4105123</td>\n",
       "      <td>148221</td>\n",
       "      <td>1100000</td>\n",
       "      <td>2011</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>90</td>\n",
       "      <td>258113</td>\n",
       "      <td>42678</td>\n",
       "      <td>1066167</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>90</td>\n",
       "      <td>2957978</td>\n",
       "      <td>40481</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>104</td>\n",
       "      <td>4231500</td>\n",
       "      <td>30479</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>97</td>\n",
       "      <td>7022940</td>\n",
       "      <td>14018</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>83</td>\n",
       "      <td>31537320</td>\n",
       "      <td>44329</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2014</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>86</td>\n",
       "      <td>18112929</td>\n",
       "      <td>52642</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>90</td>\n",
       "      <td>10042266</td>\n",
       "      <td>23021</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2005</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>103</td>\n",
       "      <td>9013113</td>\n",
       "      <td>36321</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2005</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>83</td>\n",
       "      <td>53245055</td>\n",
       "      <td>30570</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>95</td>\n",
       "      <td>5997134</td>\n",
       "      <td>36381</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>97</td>\n",
       "      <td>2508841</td>\n",
       "      <td>21746</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>92</td>\n",
       "      <td>1677838</td>\n",
       "      <td>11283</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2006</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>92</td>\n",
       "      <td>582024</td>\n",
       "      <td>30396</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1997</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>88</td>\n",
       "      <td>104077</td>\n",
       "      <td>46076</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2006</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>96</td>\n",
       "      <td>484221</td>\n",
       "      <td>23836</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>53</td>\n",
       "      <td>274661</td>\n",
       "      <td>10564</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2007</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2698 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      duration      class    votes     budget  year  rating\n",
       "0          169  309404152   471220  300000000  2007     7.1\n",
       "1          110     102055    24570  300000000  2008     6.2\n",
       "2          132   73058679   212204  263700000  2012     6.6\n",
       "3          100  200807262   294810  260000000  2010     7.8\n",
       "4          156  336530303   383056  258000000  2007     6.2\n",
       "5          156  336530303   383071  258000000  2007     6.2\n",
       "6          164  448130642  1144337  250000000  2012     8.5\n",
       "7          141  458991599   462669  250000000  2015     7.5\n",
       "8          153  301956980   321795  250000000  2009     7.5\n",
       "9          183  330249062   371639  250000000  2016     6.9\n",
       "10         136  241063875   370704  250000000  2011     6.7\n",
       "11         164  255108370   354228  250000000  2014     7.5\n",
       "12         147  407197282   272670  250000000  2016     8.2\n",
       "13         148  200074175   275868  245000000  2015     6.8\n",
       "14         178  760505847   886204  237000000  2009     7.9\n",
       "15         153  262030663   451803  230000000  2012     7.0\n",
       "16         151  423032628   522040  225000000  2006     7.3\n",
       "17         143  291021565   548573  225000000  2013     7.2\n",
       "18         150  141614023   149922  225000000  2008     6.6\n",
       "19         106  179020854   268154  225000000  2012     6.8\n",
       "20         186  258355354   483540  225000000  2013     7.9\n",
       "21         173  623279547   995415  220000000  2012     8.1\n",
       "22         173  623279547   995415  220000000  2012     8.1\n",
       "23         150   89289910   181792  215000000  2013     6.5\n",
       "24         130  234903076   175409  215000000  2013     6.4\n",
       "25         130  234903076   175413  215000000  2013     6.4\n",
       "26         104  234360014   383427  210000000  2006     6.8\n",
       "27         165  245428137   242420  210000000  2014     5.7\n",
       "28         169  200069408   240396  209000000  2006     6.1\n",
       "29         131   65173160   202382  209000000  2012     5.9\n",
       "...        ...        ...      ...        ...   ...     ...\n",
       "2668       103   53991137   202800    1500000  2010     6.8\n",
       "2669       114    1221261    38215    1500000  2000     7.9\n",
       "2670       104    3447339    29517    1500000  2013     5.8\n",
       "2671        98     406035    30314    1500000  2001     7.2\n",
       "2672       100     373967    43839    1500000  2001     6.5\n",
       "2673        84     173066    21379    1500000  2007     6.3\n",
       "2674        95       3478    22212    1500000  2008     6.7\n",
       "2675       105    1647780    65951    1300000  1998     8.1\n",
       "2676        95     695229    11369    1300000  1996     7.2\n",
       "2677       103   55153403   299127    1200000  2004     7.7\n",
       "2678       100   18488314    76151    1200000  2001     7.1\n",
       "2679       111    9180275    22145    1200000  2000     7.7\n",
       "2680        85    2199853    19986    1200000  1999     6.6\n",
       "2681       102    4105123   148221    1100000  2011     7.6\n",
       "2682        90     258113    42678    1066167  2013     7.1\n",
       "2683        90    2957978    40481    1000000  2008     7.8\n",
       "2684       104    4231500    30479    1000000  2013     7.8\n",
       "2685        97    7022940    14018    1000000  2001     6.7\n",
       "2686        83   31537320    44329    1000000  2014     5.7\n",
       "2687        86   18112929    52642    1000000  2012     5.0\n",
       "2688        90   10042266    23021    1000000  2005     5.9\n",
       "2689       103    9013113    36321    1000000  2005     7.4\n",
       "2690        83   53245055    30570    1000000  2012     4.2\n",
       "2691        95    5997134    36381    1000000  2012     7.2\n",
       "2692        97    2508841    21746    1000000  2008     7.2\n",
       "2693        92    1677838    11283    1000000  2006     7.7\n",
       "2694        92     582024    30396    1000000  1997     6.2\n",
       "2695        88     104077    46076    1000000  2006     7.4\n",
       "2696        96     484221    23836    1000000  2012     8.2\n",
       "2697        53     274661    10564    1000000  2007     7.7\n",
       "\n",
       "[2698 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "data = pd.read_csv('./movie_cleaned_data.csv',header='infer',usecols=[\"gross\",\"num_voted_users\",\"budget\", \"imdb_score\", \"title_year\", \"duration\"])\n",
    "data.columns = [\"duration\",\"class\",\"votes\",\"budget\",\"year\",\"rating\"]\n",
    "df = pd.DataFrame(data)\n",
    "df_target = df[[\"class\"]]\n",
    "df_data = df[[\"duration\",\"votes\",\"budget\",\"year\",\"rating\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>votes</th>\n",
       "      <th>budget</th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.527660</td>\n",
       "      <td>0.276807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.677966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.525424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.370213</td>\n",
       "      <td>0.121349</td>\n",
       "      <td>0.878595</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.593220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.170928</td>\n",
       "      <td>0.866221</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.472340</td>\n",
       "      <td>0.223892</td>\n",
       "      <td>0.859532</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.525424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.472340</td>\n",
       "      <td>0.223901</td>\n",
       "      <td>0.859532</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.525424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.506383</td>\n",
       "      <td>0.680802</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.915254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.408511</td>\n",
       "      <td>0.271675</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.459574</td>\n",
       "      <td>0.187124</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.587234</td>\n",
       "      <td>0.217040</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.387234</td>\n",
       "      <td>0.216479</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.506383</td>\n",
       "      <td>0.206590</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.434043</td>\n",
       "      <td>0.157640</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.864407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.438298</td>\n",
       "      <td>0.159559</td>\n",
       "      <td>0.816054</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.565957</td>\n",
       "      <td>0.525874</td>\n",
       "      <td>0.789298</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.813559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.459574</td>\n",
       "      <td>0.265153</td>\n",
       "      <td>0.765886</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.661017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.451064</td>\n",
       "      <td>0.307308</td>\n",
       "      <td>0.749164</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.711864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.417021</td>\n",
       "      <td>0.323233</td>\n",
       "      <td>0.749164</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.694915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.083968</td>\n",
       "      <td>0.749164</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.593220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.259574</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.749164</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.284201</td>\n",
       "      <td>0.749164</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.813559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.544681</td>\n",
       "      <td>0.591421</td>\n",
       "      <td>0.732441</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.544681</td>\n",
       "      <td>0.591421</td>\n",
       "      <td>0.732441</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.103096</td>\n",
       "      <td>0.715719</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.576271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.099265</td>\n",
       "      <td>0.715719</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.099268</td>\n",
       "      <td>0.715719</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.251064</td>\n",
       "      <td>0.224115</td>\n",
       "      <td>0.698997</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.139484</td>\n",
       "      <td>0.698997</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.440678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.527660</td>\n",
       "      <td>0.138270</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.508475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.365957</td>\n",
       "      <td>0.115454</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.474576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>0.246809</td>\n",
       "      <td>0.115705</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>0.293617</td>\n",
       "      <td>0.016923</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.813559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>0.251064</td>\n",
       "      <td>0.011703</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.457627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>0.225532</td>\n",
       "      <td>0.012181</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.694915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.020299</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.576271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>0.165957</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.542373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.007319</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.033570</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.694915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>0.246809</td>\n",
       "      <td>0.173519</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.039692</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.677966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>0.280851</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.593220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>0.242553</td>\n",
       "      <td>0.082947</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.762712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.019602</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.677966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>0.251064</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>0.221277</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>0.161702</td>\n",
       "      <td>0.020593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.440678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>0.174468</td>\n",
       "      <td>0.025582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.322034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.474576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>0.246809</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.728814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>0.161702</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.186441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.694915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>0.221277</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.694915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.525424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>0.182979</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.728814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>0.217021</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.864407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2698 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      duration     votes    budget  year    rating\n",
       "0     0.527660  0.276807  1.000000  0.55  0.677966\n",
       "1     0.276596  0.008734  1.000000  0.60  0.525424\n",
       "2     0.370213  0.121349  0.878595  0.80  0.593220\n",
       "3     0.234043  0.170928  0.866221  0.70  0.796610\n",
       "4     0.472340  0.223892  0.859532  0.55  0.525424\n",
       "5     0.472340  0.223901  0.859532  0.55  0.525424\n",
       "6     0.506383  0.680802  0.832776  0.80  0.915254\n",
       "7     0.408511  0.271675  0.832776  0.95  0.745763\n",
       "8     0.459574  0.187124  0.832776  0.65  0.745763\n",
       "9     0.587234  0.217040  0.832776  1.00  0.644068\n",
       "10    0.387234  0.216479  0.832776  0.75  0.610169\n",
       "11    0.506383  0.206590  0.832776  0.90  0.745763\n",
       "12    0.434043  0.157640  0.832776  1.00  0.864407\n",
       "13    0.438298  0.159559  0.816054  0.95  0.627119\n",
       "14    0.565957  0.525874  0.789298  0.65  0.813559\n",
       "15    0.459574  0.265153  0.765886  0.80  0.661017\n",
       "16    0.451064  0.307308  0.749164  0.50  0.711864\n",
       "17    0.417021  0.323233  0.749164  0.85  0.694915\n",
       "18    0.446809  0.083968  0.749164  0.60  0.593220\n",
       "19    0.259574  0.154930  0.749164  0.80  0.627119\n",
       "20    0.600000  0.284201  0.749164  0.85  0.813559\n",
       "21    0.544681  0.591421  0.732441  0.80  0.847458\n",
       "22    0.544681  0.591421  0.732441  0.80  0.847458\n",
       "23    0.446809  0.103096  0.715719  0.85  0.576271\n",
       "24    0.361702  0.099265  0.715719  0.85  0.559322\n",
       "25    0.361702  0.099268  0.715719  0.85  0.559322\n",
       "26    0.251064  0.224115  0.698997  0.50  0.627119\n",
       "27    0.510638  0.139484  0.698997  0.90  0.440678\n",
       "28    0.527660  0.138270  0.695652  0.50  0.508475\n",
       "29    0.365957  0.115454  0.695652  0.80  0.474576\n",
       "...        ...       ...       ...   ...       ...\n",
       "2668  0.246809  0.115705  0.001672  0.70  0.627119\n",
       "2669  0.293617  0.016923  0.001672  0.20  0.813559\n",
       "2670  0.251064  0.011703  0.001672  0.85  0.457627\n",
       "2671  0.225532  0.012181  0.001672  0.25  0.694915\n",
       "2672  0.234043  0.020299  0.001672  0.25  0.576271\n",
       "2673  0.165957  0.006819  0.001672  0.55  0.542373\n",
       "2674  0.212766  0.007319  0.001672  0.60  0.610169\n",
       "2675  0.255319  0.033570  0.001003  0.10  0.847458\n",
       "2676  0.212766  0.000811  0.001003  0.00  0.694915\n",
       "2677  0.246809  0.173519  0.000669  0.40  0.779661\n",
       "2678  0.234043  0.039692  0.000669  0.25  0.677966\n",
       "2679  0.280851  0.007278  0.000669  0.20  0.779661\n",
       "2680  0.170213  0.005983  0.000669  0.15  0.593220\n",
       "2681  0.242553  0.082947  0.000334  0.75  0.762712\n",
       "2682  0.191489  0.019602  0.000221  0.85  0.677966\n",
       "2683  0.191489  0.018283  0.000000  0.60  0.796610\n",
       "2684  0.251064  0.012280  0.000000  0.85  0.796610\n",
       "2685  0.221277  0.002401  0.000000  0.25  0.610169\n",
       "2686  0.161702  0.020593  0.000000  0.90  0.440678\n",
       "2687  0.174468  0.025582  0.000000  0.80  0.322034\n",
       "2688  0.191489  0.007804  0.000000  0.45  0.474576\n",
       "2689  0.246809  0.015787  0.000000  0.45  0.728814\n",
       "2690  0.161702  0.012335  0.000000  0.80  0.186441\n",
       "2691  0.212766  0.015823  0.000000  0.80  0.694915\n",
       "2692  0.221277  0.007039  0.000000  0.60  0.694915\n",
       "2693  0.200000  0.000759  0.000000  0.50  0.779661\n",
       "2694  0.200000  0.012231  0.000000  0.05  0.525424\n",
       "2695  0.182979  0.021641  0.000000  0.50  0.728814\n",
       "2696  0.217021  0.008293  0.000000  0.80  0.864407\n",
       "2697  0.034043  0.000328  0.000000  0.55  0.779661\n",
       "\n",
       "[2698 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_values = scaler.fit_transform(df_data.values)\n",
    "df_data_scaled = pd.DataFrame(scaled_values, columns=df_data.columns)\n",
    "scaled_target_values = scaler.fit_transform(df_target.values)\n",
    "df_target_scaled = pd.DataFrame(scaled_target_values,columns =df_target.columns)\n",
    "df_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_data, df_target,\n",
    "                                                    train_size=0.75, test_size=0.25,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BackendContext.__del__ of <autosklearn.util.backend.BackendContext object at 0x104efe0f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/autosklearn/util/backend.py\", line 127, in __del__\n",
      "    self.delete_directories(force=False)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/autosklearn/util/backend.py\", line 136, in delete_directories\n",
      "    \"auto-sklearn.\" % self.output_directory)\n",
      "ValueError: Failed to delete output dir: ./auto_sklearn/autosklearn_regression_example_out because auto-sklearn did not create it. Please make sure that the specified output dir does not exist when instantiating auto-sklearn.\n",
      "Exception ignored in: <bound method BackendContext.__del__ of <autosklearn.util.backend.BackendContext object at 0x1a0c96a6a0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/autosklearn/util/backend.py\", line 127, in __del__\n",
      "    self.delete_directories(force=False)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/autosklearn/util/backend.py\", line 136, in delete_directories\n",
      "    \"auto-sklearn.\" % self.output_directory)\n",
      "ValueError: Failed to delete output dir: ./auto_sklearn/autosklearn_regression_example_out because auto-sklearn did not create it. Please make sure that the specified output dir does not exist when instantiating auto-sklearn.\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_test.mean(), inplace=True)\n",
    "y_train.fillna(y_train.mean(),inplace=True)\n",
    "y_test.fillna(y_train.mean(),inplace=True)\n",
    "# print(X_train)\n",
    "# print(X_test)\n",
    "# print(y_train)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/autosklearn/automl.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Will change shape via np.ravel().\n",
      "  y = self._check_y(y)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2019-02-20 22:09:12,584:AutoMLSMBO(1)::movie_prediction] Could not find meta-data directory /anaconda3/lib/python3.6/site-packages/autosklearn/metalearning/files/r2_regression_dense\n",
      "[WARNING] [2019-02-20 22:09:12,615:EnsembleBuilder(1):movie_prediction] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-02-20 22:09:12,639:EnsembleBuilder(1):movie_prediction] No models better than random - using Dummy Score!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 1 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:29] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:30] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:30] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:30] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:30] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:30] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[22:15:30] src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/anaconda3/lib/python3.6/site-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnRegressor(delete_output_folder_after_terminate=True,\n",
       "           delete_tmp_folder_after_terminate=True,\n",
       "           disable_evaluator_output=False, ensemble_memory_limit=1024,\n",
       "           ensemble_nbest=50, ensemble_size=50, exclude_estimators=None,\n",
       "           exclude_preprocessors=None, get_smac_object_callback=None,\n",
       "           include_estimators=None, include_preprocessors=None,\n",
       "           initial_configurations_via_metalearning=25, logging_config=None,\n",
       "           ml_memory_limit=3072, n_jobs=None,\n",
       "           output_folder='./auto_sklearn/autosklearn_regression_example_out',\n",
       "           per_run_time_limit=60, resampling_strategy='holdout',\n",
       "           resampling_strategy_arguments=None, seed=1, shared_mode=False,\n",
       "           smac_scenario_args=None, time_left_for_this_task=600,\n",
       "           tmp_folder='./auto_sklearn/autosklearn_regression_example_tmp')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_types = (['numerical'] * 5)\n",
    "automl = autosklearn.regression.AutoSklearnRegressor(\n",
    "    time_left_for_this_task=600,\n",
    "    per_run_time_limit=60,\n",
    "    tmp_folder='./auto_sklearn/autosklearn_regression_example_tmp',\n",
    "    output_folder='./auto_sklearn/autosklearn_regression_example_out',\n",
    ")\n",
    "automl.fit(X_train, y_train, dataset_name='movie_prediction',\n",
    "           feat_type=feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.420000, SimpleRegressionPipeline({'categorical_encoding:__choice__': 'one_hot_encoding', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'kernel_pca', 'regressor:__choice__': 'ridge_regression', 'rescaling:__choice__': 'quantile_transformer', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'preprocessor:kernel_pca:kernel': 'rbf', 'preprocessor:kernel_pca:n_components': 1572, 'regressor:ridge_regression:alpha': 0.3163643086831626, 'regressor:ridge_regression:fit_intercept': 'True', 'regressor:ridge_regression:tol': 2.7829755586403822e-05, 'rescaling:quantile_transformer:n_quantiles': 1283, 'rescaling:quantile_transformer:output_distribution': 'normal', 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.0026155994148570534, 'preprocessor:kernel_pca:gamma': 0.020591800488796684},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "(0.240000, SimpleRegressionPipeline({'categorical_encoding:__choice__': 'one_hot_encoding', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'adaboost', 'rescaling:__choice__': 'minmax', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False', 'preprocessor:fast_ica:algorithm': 'deflation', 'preprocessor:fast_ica:fun': 'logcosh', 'preprocessor:fast_ica:whiten': 'False', 'regressor:adaboost:learning_rate': 0.02694174148192237, 'regressor:adaboost:loss': 'square', 'regressor:adaboost:max_depth': 9, 'regressor:adaboost:n_estimators': 442},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "(0.120000, SimpleRegressionPipeline({'categorical_encoding:__choice__': 'no_encoding', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'polynomial', 'regressor:__choice__': 'xgradient_boosting', 'rescaling:__choice__': 'robust_scaler', 'preprocessor:polynomial:degree': 2, 'preprocessor:polynomial:include_bias': 'True', 'preprocessor:polynomial:interaction_only': 'True', 'regressor:xgradient_boosting:base_score': 0.5, 'regressor:xgradient_boosting:booster': 'gbtree', 'regressor:xgradient_boosting:colsample_bylevel': 0.7751453051974666, 'regressor:xgradient_boosting:colsample_bytree': 0.5730474197261233, 'regressor:xgradient_boosting:gamma': 0, 'regressor:xgradient_boosting:learning_rate': 0.11581951080801708, 'regressor:xgradient_boosting:max_delta_step': 0, 'regressor:xgradient_boosting:max_depth': 5, 'regressor:xgradient_boosting:min_child_weight': 12, 'regressor:xgradient_boosting:n_estimators': 512, 'regressor:xgradient_boosting:reg_alpha': 4.398877472461938e-09, 'regressor:xgradient_boosting:reg_lambda': 5.966495697287376e-08, 'regressor:xgradient_boosting:scale_pos_weight': 1, 'regressor:xgradient_boosting:subsample': 0.9852052421671279, 'rescaling:robust_scaler:q_max': 0.7730957522615305, 'rescaling:robust_scaler:q_min': 0.25478795009204463},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "(0.120000, SimpleRegressionPipeline({'categorical_encoding:__choice__': 'one_hot_encoding', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'no_preprocessing', 'regressor:__choice__': 'adaboost', 'rescaling:__choice__': 'normalize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'regressor:adaboost:learning_rate': 0.7962428667659348, 'regressor:adaboost:loss': 'square', 'regressor:adaboost:max_depth': 7, 'regressor:adaboost:n_estimators': 178, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.03853039582263623},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "(0.100000, SimpleRegressionPipeline({'categorical_encoding:__choice__': 'one_hot_encoding', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'no_preprocessing', 'regressor:__choice__': 'gradient_boosting', 'rescaling:__choice__': 'minmax', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'regressor:gradient_boosting:learning_rate': 0.5838227333466169, 'regressor:gradient_boosting:loss': 'lad', 'regressor:gradient_boosting:max_depth': 4, 'regressor:gradient_boosting:max_features': 0.7383192977996376, 'regressor:gradient_boosting:max_leaf_nodes': 'None', 'regressor:gradient_boosting:min_impurity_decrease': 0.0, 'regressor:gradient_boosting:min_samples_leaf': 15, 'regressor:gradient_boosting:min_samples_split': 13, 'regressor:gradient_boosting:min_weight_fraction_leaf': 0.0, 'regressor:gradient_boosting:n_estimators': 97, 'regressor:gradient_boosting:subsample': 0.8465413689882479, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.02181626803945325},\n",
      "dataset_properties={\n",
      "  'task': 4,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})),\n",
      "]\n",
      "R2 score: 0.6788199978062189\n"
     ]
    }
   ],
   "source": [
    "print(automl.show_models())\n",
    "predictions = automl.predict(X_test)\n",
    "print(\"R2 score:\", sklearn.metrics.r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_value</th>\n",
       "      <th>predicted_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>17804273</td>\n",
       "      <td>1.117580e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>36447959</td>\n",
       "      <td>1.858149e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>34293771</td>\n",
       "      <td>1.292152e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>13622333</td>\n",
       "      <td>6.208733e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>202351611</td>\n",
       "      <td>2.362048e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>1110186</td>\n",
       "      <td>7.775952e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>30226144</td>\n",
       "      <td>7.000246e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>323505540</td>\n",
       "      <td>1.009222e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>5348317</td>\n",
       "      <td>1.409746e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>5709616</td>\n",
       "      <td>1.833747e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>190871240</td>\n",
       "      <td>1.118441e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>14018364</td>\n",
       "      <td>2.632354e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>65452312</td>\n",
       "      <td>1.025616e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>5932060</td>\n",
       "      <td>2.968889e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>63992328</td>\n",
       "      <td>6.665902e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>101334374</td>\n",
       "      <td>5.770986e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>42638165</td>\n",
       "      <td>3.109530e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>40270895</td>\n",
       "      <td>2.836486e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>115603980</td>\n",
       "      <td>5.966166e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>87025093</td>\n",
       "      <td>3.700468e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>43929341</td>\n",
       "      <td>6.691851e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>4443403</td>\n",
       "      <td>1.136819e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>131920333</td>\n",
       "      <td>1.621174e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>5516708</td>\n",
       "      <td>2.414342e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>18488314</td>\n",
       "      <td>1.178085e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>55865715</td>\n",
       "      <td>2.137641e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>173381405</td>\n",
       "      <td>6.078868e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>3293258</td>\n",
       "      <td>1.773501e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>148383780</td>\n",
       "      <td>8.418185e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>10166502</td>\n",
       "      <td>2.880636e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>67155742</td>\n",
       "      <td>8.130875e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>12570442</td>\n",
       "      <td>1.007753e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>118311368</td>\n",
       "      <td>1.631245e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>25359200</td>\n",
       "      <td>2.814536e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>83906114</td>\n",
       "      <td>5.916312e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>20772796</td>\n",
       "      <td>5.434983e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>15483540</td>\n",
       "      <td>2.141243e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>56876365</td>\n",
       "      <td>6.473880e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>91188905</td>\n",
       "      <td>6.939671e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>277313371</td>\n",
       "      <td>1.276578e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>75530832</td>\n",
       "      <td>6.438758e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>3335839</td>\n",
       "      <td>9.617260e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>80021740</td>\n",
       "      <td>4.482038e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>37035515</td>\n",
       "      <td>3.574850e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>88200225</td>\n",
       "      <td>7.446923e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>45542421</td>\n",
       "      <td>2.813495e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>176740650</td>\n",
       "      <td>1.743935e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>13034417</td>\n",
       "      <td>1.558976e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>51774002</td>\n",
       "      <td>5.664981e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>20101861</td>\n",
       "      <td>3.786757e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>75367693</td>\n",
       "      <td>5.492652e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>37788228</td>\n",
       "      <td>2.383482e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>1754319</td>\n",
       "      <td>6.029753e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>8279017</td>\n",
       "      <td>1.239104e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>37752931</td>\n",
       "      <td>2.950045e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>317011114</td>\n",
       "      <td>2.137181e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>47860214</td>\n",
       "      <td>2.896771e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>261970615</td>\n",
       "      <td>1.344098e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>104007828</td>\n",
       "      <td>3.045003e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>17593391</td>\n",
       "      <td>6.291405e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      expected_value  predicted_value\n",
       "1866        17804273     1.117580e+07\n",
       "1608        36447959     1.858149e+07\n",
       "114         34293771     1.292152e+08\n",
       "2634        13622333     6.208733e+06\n",
       "59         202351611     2.362048e+08\n",
       "2163         1110186     7.775952e+06\n",
       "2034        30226144     7.000246e+06\n",
       "516        323505540     1.009222e+08\n",
       "2306         5348317     1.409746e+07\n",
       "2658         5709616     1.833747e+07\n",
       "234        190871240     1.118441e+08\n",
       "1376        14018364     2.632354e+07\n",
       "312         65452312     1.025616e+08\n",
       "1218         5932060     2.968889e+07\n",
       "188         63992328     6.665902e+07\n",
       "1664       101334374     5.770986e+07\n",
       "1973        42638165     3.109530e+07\n",
       "1709        40270895     2.836486e+07\n",
       "658        115603980     5.966166e+07\n",
       "2551        87025093     3.700468e+07\n",
       "242         43929341     6.691851e+07\n",
       "2408         4443403     1.136819e+07\n",
       "214        131920333     1.621174e+08\n",
       "1642         5516708     2.414342e+07\n",
       "2678        18488314     1.178085e+07\n",
       "2271        55865715     2.137641e+07\n",
       "1333       173381405     6.078868e+07\n",
       "2599         3293258     1.773501e+07\n",
       "313        148383780     8.418185e+07\n",
       "491         10166502     2.880636e+07\n",
       "...              ...              ...\n",
       "255         67155742     8.130875e+07\n",
       "2291        12570442     1.007753e+07\n",
       "266        118311368     1.631245e+08\n",
       "2559        25359200     2.814536e+07\n",
       "1093        83906114     5.916312e+07\n",
       "2479        20772796     5.434983e+06\n",
       "2111        15483540     2.141243e+07\n",
       "1242        56876365     6.473880e+07\n",
       "460         91188905     6.939671e+07\n",
       "1231       277313371     1.276578e+08\n",
       "791         75530832     6.438758e+07\n",
       "2649         3335839     9.617260e+06\n",
       "770         80021740     4.482038e+07\n",
       "1032        37035515     3.574850e+07\n",
       "706         88200225     7.446923e+07\n",
       "1472        45542421     2.813495e+07\n",
       "369        176740650     1.743935e+08\n",
       "2062        13034417     1.558976e+07\n",
       "780         51774002     5.664981e+07\n",
       "1001        20101861     3.786757e+07\n",
       "1220        75367693     5.492652e+07\n",
       "1214        37788228     2.383482e+07\n",
       "2312         1754319     6.029753e+06\n",
       "2383         8279017     1.239104e+07\n",
       "1111        37752931     2.950045e+07\n",
       "63         317011114     2.137181e+08\n",
       "2020        47860214     2.896771e+07\n",
       "308        261970615     1.344098e+08\n",
       "2499       104007828     3.045003e+07\n",
       "479         17593391     6.291405e+07\n",
       "\n",
       "[675 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\"expected_value\":y_test[\"class\"],\"predicted_value\":predictions})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./results_autosklearn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011663252968304.8\n"
     ]
    }
   ],
   "source": [
    "mse_sum = 0\n",
    "for index, row in result.iterrows():\n",
    "    mse_sum += (row[\"expected_value\"] - row[\"predicted_value\"])**2\n",
    "mse = mse_sum / len(result)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
